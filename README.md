# Claude Cowork Clone

A multi-LLM cowork platform that replicates Claude's cowork functionality while supporting multiple LLM backends.

## Overview

This project aims to create a flexible cowork environment where users can collaborate with AI assistants powered by different LLM providers. The initial focus is on supporting:

- **Anthropic Claude** - Via Anthropic Pro subscription
- **Ollama** - For local LLM inference

## Features (Planned)

- Multi-LLM backend support with a unified interface
- Switchable LLM providers during sessions
- Local-first option with Ollama for privacy-conscious users
- Cowork-style collaborative interface
- Conversation persistence and history
- Context management across sessions

## Project Structure

```
claude-cowork-clone/
├── docs/               # Documentation, user stories, and development plans
├── src/                # Source code (TBD)
├── tests/              # Test files (TBD)
└── README.md
```

## Supported LLM Backends

### Anthropic Claude
Requires an Anthropic Pro subscription. Uses the official Anthropic API.

### Ollama
Run LLMs locally using [Ollama](https://ollama.ai/). Supports various open-source models like Llama, Mistral, and others.

## Getting Started

*Coming soon - project is in planning phase*

## Documentation

See the [docs/](./docs/) directory for:
- User stories
- Development plans
- Architecture decisions
- API specifications

## License

TBD

## Contributing

TBD
